{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/google/eng-edu/blob/main/ml/cc/exercises/pandas_dataframe_ultraquick_tutorial.ipynb","timestamp":1705427234216}],"private_outputs":true,"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install --upgrade kaggle\n","\n"],"metadata":{"id":"KlpmLHu-G8kh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"1IcBHuwlHA3T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! mkdir ~/.kaggle"],"metadata":{"id":"rTeqrkrFHwuC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! cp /content/drive/MyDrive/kaggle.json ~/.kaggle/kaggle.json"],"metadata":{"id":"VW4QtZNpHw2p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! chmod 600 ~/.kaggle/kaggle.json"],"metadata":{"id":"THqCf8-BIQwW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! kaggle datasets download -d mariaherrerot/messidor2preprocess"],"metadata":{"id":"LfZlPfs8IQzF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! kaggle competitions download aptos2019-blindness-detection"],"metadata":{"id":"IWuwUR_sNpz6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! unzip aptos2019-blindness-detection.zip"],"metadata":{"id":"NvIsJnn1IQ10"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! unzip messidor2preprocess.zip"],"metadata":{"id":"j6xeFkStNo0-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n"],"metadata":{"id":"3PL7ga0QLlaC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["aptos_train = pd.read_csv('/content/train.csv')\n","aptos_test = pd.read_csv('/content/test.csv')"],"metadata":{"id":"n7Qg8BKfLldD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["aptos_train.info()"],"metadata":{"id":"BGqVM4IkLlfx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["idrid_train = pd.read_csv('/content/drive/MyDrive/ML/capestone/B. Disease Grading/2. Groundtruths/training.csv')\n","idrid_test = pd.read_csv('/content/drive/MyDrive/ML/capestone/B. Disease Grading/2. Groundtruths/test.csv')"],"metadata":{"id":"dXHpB1mILlio"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["messidor_df = pd.read_csv(\"/content/messidor_data.csv\")"],"metadata":{"id":"wLoLU-xJLllG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["aptos_freq = aptos_train['diagnosis'].value_counts()"],"metadata":{"id":"IohbhcIMVyxr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["aptos_freq"],"metadata":{"id":"URJHdBZ5Vy0h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["idrid_train['Retinopathy grade'].value_counts()"],"metadata":{"id":"e3OViFh2Vy3A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["messidor_df['diagnosis'].value_counts()"],"metadata":{"id":"QFnYrh9oVy5x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n"],"metadata":{"id":"DaFvy41VVy8F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["img = cv2.imread('/content/train_images/000c1434d8d7.png')"],"metadata":{"id":"E3qiW5UDVy-q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n"],"metadata":{"id":"UOpGjrxd0uJd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.imshow(img)"],"metadata":{"id":"xNhgZjoW1l4M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)"],"metadata":{"id":"SVeP111X1T3G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.imshow(gray_img)"],"metadata":{"id":"-RIQsyScya59"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Apply Otsu's thresholding\n","_, otsu_threshold = cv2.threshold(gray_img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)"],"metadata":{"id":"0l3jkqq33eS_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.imshow(otsu_threshold,cmap='gray')"],"metadata":{"id":"qTPX5uUl83j0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Convert the binary mask to uint8 type\n","otsu_threshold_uint8 = otsu_threshold.astype('uint8')"],"metadata":{"id":"DmD2EWkb83me"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Find contours in the binary mask\n","contours, _ = cv2.findContours(otsu_threshold_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)"],"metadata":{"id":"kCXwov7G83pP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Sort contours based on their area in descending order\n","contours_sorted = sorted(contours, key=cv2.contourArea)"],"metadata":{"id":"7hbWyVBSAWrA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create a copy of the original image\n","img_with_roi = img.copy()"],"metadata":{"id":"qXSybYU3B5pu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["largest_contour = contours_sorted[0]\n","x, y, w, h = cv2.boundingRect(largest_contour)"],"metadata":{"id":"IIVYAC1tB5m5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Crop the region of interest (ROI) from the original image\n","roi = img[y:y+h, x:x+w]"],"metadata":{"id":"kZ3twqLkB5kh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.imshow(roi, cmap='gray')\n","plt.title('Extracted ROI')"],"metadata":{"id":"u6I44fqaB5h9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"sHlgVGdjQjVd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["_, binary_image = cv2.threshold(roi, 0, 255, cv2.THRESH_BINARY)\n"],"metadata":{"id":"92GfDO5vL4St"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.imshow(binary_image)"],"metadata":{"id":"NfXpsPFI3ndl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["kernel_size = (10, 10)\n","kernel = cv2.getStructuringElement(cv2.MORPH_RECT, kernel_size)\n","opened_image = cv2.morphologyEx(binary_image, cv2.MORPH_OPEN, kernel)\n"],"metadata":{"id":"twHsrye5L4VW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.imshow(opened_image)\n"],"metadata":{"id":"Kagjiz1HL4YA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["opened_image.shape"],"metadata":{"id":"vVC_tOBfL4ca"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["roi.shape"],"metadata":{"id":"S3fra3lnNx9R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"DEQ7qO6rPIAG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["opened_image = opened_image.astype('uint8')\n","\n"],"metadata":{"id":"dJfDhdrQN2PE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gray_image = cv2.cvtColor(opened_image, cv2.COLOR_BGR2GRAY)\n"],"metadata":{"id":"ht-sAD72PI-Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.imshow(opened_image)"],"metadata":{"id":"GS6CkXRQPOSe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result_image = cv2.bitwise_and(roi, opened_image)"],"metadata":{"id":"Zchoh9PLN2MM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.imshow(result_image)"],"metadata":{"id":"EQC28PGmPhoK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["denoised_image = cv2.fastNlMeansDenoisingColored(result_image, None, 1, 1, 7, 21)\n"],"metadata":{"id":"tsgjkT6aTN9D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.imshow(denoised_image)"],"metadata":{"id":"OjHG2qQNTN6T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["yuv_image = cv2.cvtColor(denoised_image, cv2.COLOR_BGR2YUV)"],"metadata":{"id":"kALElLWzTN39"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.imshow(yuv_image)"],"metadata":{"id":"bizYPLY0TN1b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_channel = yuv_image[:, :, 0]"],"metadata":{"id":"3m5Egj1_TNyf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.imshow(y_channel)"],"metadata":{"id":"OwfLO1VWTNtp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["clahe = cv2.createCLAHE(clipLimit=0.5, tileGridSize=(8, 8))\n","clahe_output = clahe.apply(y_channel)"],"metadata":{"id":"VhR0bznQTNqp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.imshow(clahe_output)"],"metadata":{"id":"UhTjPotmVRzg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["enhanced_yuv_image = cv2.merge([clahe_output, yuv_image[:, :, 1], yuv_image[:, :, 2]])"],"metadata":{"id":"NAIr7BG3VRw5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.imshow(enhanced_yuv_image)"],"metadata":{"id":"XyhVZfx-W6JV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 5: Convert the enhanced image back to BGR color space\n","enhanced_bgr_image = cv2.cvtColor(enhanced_yuv_image, cv2.COLOR_YUV2BGR)"],"metadata":{"id":"2vBpXDrbVRuj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.imshow(enhanced_bgr_image)"],"metadata":{"id":"FGhxwhXBW_vp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["arr = [[0,0,0],[0,255,0],[1,1,1]]"],"metadata":{"id":"-yzckTWdZcPB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["aptos_train['diagnosis'].value_counts()"],"metadata":{"id":"EeQn82bzZcJs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["messidor_df['diagnosis'].value_counts()"],"metadata":{"id":"cDMOXkQnZcGT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["idrid_train['Retinopathy grade'].value_counts()"],"metadata":{"id":"6nKY6WeGbKys"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["aptos_train.head(8)"],"metadata":{"id":"LMgMViI7dXzB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["aptos_train['diagnosis'].value_counts()"],"metadata":{"id":"z7hSCkTTl1SU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["aptos_subset_dataframe = aptos_train.head(300)"],"metadata":{"id":"T2tV8UtBm6iO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["aptos_subset_dataframe['diagnosis'].value_counts()"],"metadata":{"id":"XvzQyg1ym6fS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["idrid_subset_dataframe = idrid_train.head(300)"],"metadata":{"id":"BlOUQmv1m6aM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["idrid_subset_dataframe['Retinopathy grade'].value_counts()"],"metadata":{"id":"Q1Ddy0dnnn8o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["idrid_train['Retinopathy grade'].value_counts()"],"metadata":{"id":"cQ9M1zm1nn6_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["messidor_subset_dataframe = messidor_df.head(300)"],"metadata":{"id":"0Gu3RHVsoHJ6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["messidor_subset_dataframe['diagnosis'].value_counts()"],"metadata":{"id":"9JjnXo6voHGg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["messidor_df['diagnosis'].value_counts()"],"metadata":{"id":"xc74epMXnn3k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os"],"metadata":{"id":"oAAqhIsDeewP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["aptos_data = pd.DataFrame(columns=['id_code', 'image','label'])"],"metadata":{"id":"7UWH9V5JbWRO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["aptos_data.head()"],"metadata":{"id":"77xAGIhvb0-0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["aptos_train_path = '/content/train_images'"],"metadata":{"id":"ZbSCSPfhdSue"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["aptos_data.info()"],"metadata":{"id":"C5U7q8BQezoo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for index, row in aptos_subset_dataframe.iterrows():\n","    # Extract id_code and diagnosis from the DataFrame\n","    id_code = row['id_code']\n","    diagnosis = row['diagnosis']\n","    image_path = os.path.join(aptos_train_path, f\"{id_code}.png\")\n","    img = cv2.imread(image_path)\n","    aptos_data=aptos_data.append({'id_code': 1, 'image': img, 'label':diagnosis}, ignore_index=True)\n"],"metadata":{"id":"VHg-KjYieUAc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["aptos_data.shape"],"metadata":{"id":"tM2ZlRrx75Jw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# idrid_data = pd.DataFrame(columns=['id_code', 'image','label'])"],"metadata":{"id":"wjdK4xxtouds"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# idrid_subset_dataframe.head(5)"],"metadata":{"id":"NJSE_63upHZU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# idrid_train_path = '/content/drive/MyDrive/ML/capestone/B. Disease Grading/1. Original Images/a. Training Set/'"],"metadata":{"id":"9nnTmede7IFm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# for index, row in idrid_subset_dataframe.iterrows():\n","#     # Extract id_code and diagnosis from the DataFrame\n","#     id_code = row['Image name']\n","#     diagnosis = row['Retinopathy grade']\n","#     image_path = os.path.join(idrid_train_path, f\"{id_code}.jpg\")\n","#     img = cv2.imread(image_path)\n","#     idrid_data=idrid_data.append({'id_code': 1, 'image': img, 'label':diagnosis}, ignore_index=True)"],"metadata":{"id":"ZL_VgNWKougd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["aptos_data['label'].value_counts()"],"metadata":{"id":"HW04O4QWoujI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def preprocess(img):\n","  gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","  # Apply Otsu's thresholding\n","  _, otsu_threshold = cv2.threshold(gray_img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n","  # Convert the binary mask to uint8 type\n","  otsu_threshold_uint8 = otsu_threshold.astype('uint8')\n","  # Find contours in the binary mask\n","  contours, _ = cv2.findContours(otsu_threshold_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","  # Sort contours based on their area in descending order\n","  contours_sorted = sorted(contours, key=cv2.contourArea)\n","  largest_contour = contours_sorted[0]\n","  x, y, w, h = cv2.boundingRect(largest_contour)\n","  # Crop the region of interest (ROI) from the original image\n","  roi = img[y:y+h, x:x+w]\n","  _, binary_image = cv2.threshold(roi, 0, 255, cv2.THRESH_BINARY)\n","  kernel_size = (10, 10)\n","  kernel = cv2.getStructuringElement(cv2.MORPH_RECT, kernel_size)\n","  opened_image = cv2.morphologyEx(binary_image, cv2.MORPH_OPEN, kernel)\n","  opened_image = opened_image.astype('uint8')\n","  gray_image = cv2.cvtColor(opened_image, cv2.COLOR_BGR2GRAY)\n","  result_image = cv2.bitwise_and(roi, opened_image)\n","  denoised_image = cv2.fastNlMeansDenoisingColored(result_image, None, 1, 1, 7, 21)\n","  yuv_image = cv2.cvtColor(denoised_image, cv2.COLOR_BGR2YUV)\n","  y_channel = yuv_image[:, :, 0]\n","  clahe = cv2.createCLAHE(clipLimit=0.5, tileGridSize=(8, 8))\n","  clahe_output = clahe.apply(y_channel)\n","  enhanced_yuv_image = cv2.merge([clahe_output, yuv_image[:, :, 1], yuv_image[:, :, 2]])\n","  # Step 5: Convert the enhanced image back to BGR color space\n","  enhanced_bgr_image = cv2.cvtColor(enhanced_yuv_image, cv2.COLOR_YUV2BGR)\n","  resized_image = cv2.resize(enhanced_bgr_image, (512, 512))\n","  return resized_image\n","\n","\n"],"metadata":{"id":"ScXyS7Dzoulx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"PHB2rlI-EOim"}},{"cell_type":"code","source":["img = cv2.imread('/content/train_images/000c1434d8d7.png')"],"metadata":{"id":"oakgx_NLouoX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.imshow(img)"],"metadata":{"id":"V3_yChexouq0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["img = preprocess(img)"],"metadata":{"id":"i735GBhLoutD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.imshow(img)"],"metadata":{"id":"lpTKO-dzGxGg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["aptos_data = aptos_data.drop(columns='id_code')\n"],"metadata":{"id":"hkAIip1IHkzC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["aptos_data.head(2)"],"metadata":{"id":"ES3xN6uLHkvm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image=  aptos_data['image'].iloc[0]"],"metadata":{"id":"1SYACeE7Hkp1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.imshow(image)"],"metadata":{"id":"mG9x6HQiHknS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["aptos_data['image'].iloc[0].shape"],"metadata":{"id":"FufLalabJm9i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for index, row in aptos_data.iterrows():\n","    img =  row['image']\n","    # Preprocess the image\n","    print(\"processing img\",index)\n","    processed_image = preprocess(img)\n","    print(\"done\")\n","    # Update the 'image' column with the processed image\n","    aptos_data.at[index, 'image'] = processed_image"],"metadata":{"id":"bty_29u6HkkJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["aptos_data['label'].value_counts()"],"metadata":{"id":"ov3OkSnvHkhQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","def brightness_altering(image, factor):\n","    return cv2.addWeighted(image, factor, np.zeros_like(image), 0, 0)\n","\n","def contrast_altering(image, factor):\n","    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","    gray = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)\n","    return cv2.addWeighted(image, factor, gray, 1 - factor, 0)\n","\n","def color_altering(image, factor):\n","    return cv2.addWeighted(image, factor, np.zeros_like(image), 0, 0)\n","\n","def sharpness_altering(image, factor):\n","    blurred = cv2.GaussianBlur(image, (0, 0), factor)\n","    return cv2.addWeighted(image, 1.5, blurred, -0.5, 0)"],"metadata":{"id":"-7dcSPgdWLcT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def apply_augmentation(img, factor, augmentation_type):\n","    if augmentation_type == 'brightness':\n","        return brightness_altering(img, factor)\n","    elif augmentation_type == 'contrast':\n","        return contrast_altering(img, factor)\n","    elif augmentation_type == 'color':\n","        return color_altering(img, factor)\n","    elif augmentation_type == 'sharpness':\n","        return sharpness_altering(img, factor)\n","    else:\n","        return img"],"metadata":{"id":"P8rgKiALWLYV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import random"],"metadata":{"id":"-QHHTkEzgtfM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["aptos_data.head(1)"],"metadata":{"id":"13F1PneMln-0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Iterate over the dataset\n","for index, row in aptos_data.iterrows():\n","    print(\"img\",index)\n","    label = row['label']\n","    img = row['image']\n","\n","    # Define the number of additional copies based on the label\n","    num_copies = {\n","        0: 0,\n","        1: 5,\n","        2: 1,\n","        3: 7,\n","        4: 5\n","    }.get(label, 0)\n","\n","    # Apply photometric augmentation and create additional copies\n","    for _ in range(num_copies):\n","        # Choose the type of augmentation based on your conditions\n","       augmentation_type = random.choice(['brightness', 'contrast', 'color', 'sharpness'])\n","       if augmentation_type:\n","            augmented_img = apply_augmentation(img, 1.8, augmentation_type)\n","            new_row = {'label': label, 'image': augmented_img}\n","            aptos_data = aptos_data.append(new_row, ignore_index=True)\n","\n","\n"],"metadata":{"id":"WGR5klRtWK_1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["aptos_data['label'].value_counts()"],"metadata":{"id":"Gg-LIS3Klz3O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","from tensorflow.keras.optimizers import Adam\n"],"metadata":{"id":"C3Ako3rGjun2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Define the model\n","model = Sequential()\n","\n","# Block 1\n","model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(224, 224, 3)))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","# Block 2\n","model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","# Block 3\n","model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","# Flatten layer\n","model.add(Flatten())\n","\n","# Dense layer with dropout\n","model.add(Dense(512, activation='relu'))\n","model.add(Dropout(0.5))\n","\n","# Classification dense layer\n","model.add(Dense(5, activation='softmax'))\n","\n","lr = 0.0001  # Set your desired learning rate\n","optimizer = Adam(learning_rate=lr)\n","model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n","\n","\n","# Display the model summary\n","model.summary()\n"],"metadata":{"id":"lWNXnXiljuk2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train = aptos_data['image']"],"metadata":{"id":"uYgRfx5gnvIq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train_resized = [cv2.resize(img, (224, 224)) for img in X_train]"],"metadata":{"id":"-W7CA9UgnwB-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train_resized = np.array(X_train_resized)"],"metadata":{"id":"tEZLO-hkn0C2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras.utils import to_categorical"],"metadata":{"id":"KwBY_mAEoHco"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_train = aptos_data['label']"],"metadata":{"id":"u4HwkNW1oQUE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_train_encoded = to_categorical(y_train, num_classes=5)"],"metadata":{"id":"nWeXruwimiQ8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_train_encoded[0]\n","type(y_train_encoded)"],"metadata":{"id":"ar3CTwdBnP0H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train the model\n","history = model.fit(X_train_resized, y_train_encoded, epochs=100, batch_size=64)"],"metadata":{"id":"mii5jHQIjuiC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"NzQp1nnDjufZ"},"execution_count":null,"outputs":[]}]}